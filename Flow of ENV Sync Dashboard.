
✅ ENV_SYNC Dashboard — Complete Algorithm (End-to-End Execution Logic)
________________________________________
1. LOGIN FLOW ( /login )
Algorithm
1.	User enters username + password.
2.	Read conf/users.json.
3.	Check:
o	If username exists.
o	If password matches hashed password.
4.	If failure → return error UI.
5.	If success:
o	Create signed session cookie with expiry.
o	Redirect to /dashboard.
2. HOME Module (/dashboard)
When Page Loads,
The Summary of alerts/reminder/failures/success from all other module will be visible here.
3. MASTER SYNC MODULE ( /master-sync )
A. When Page Loads
Algorithm
1.	Read last 10 rows from DB table master_sync_runs.
2.	Render:
o	Buttons (Generate / Schedule)
o	Latest report summary (from latest TS folder)
o	History table.

B. User Clicks: “Generate Master Sync Report”
Step 1 — Ask Modal
Take production dump? Yes/No
C. If YES → Take Production Dump
Algorithm
1.	Read command from:
conf/conf_path.json → prod_dump_command variable.
2.	Execute using subprocess.
3.	If return code != 0:
Mark run as "FAILED_PROD_DUMP"
Log stdout/stderr to DB + failure UI
	Show the failure notification in /dashboard UI and /master_sync
	Send a mail to conf/setup.json  email_cc variable’s recipient list. (use mutt command to send mail)
STOP.
D. Setup Timestamp Folder
Algorithm
1.	TS = current timestamp (YYYY_MM_DD_HH:MM:SS).
2.	Create:
conf/conf_path.json → base_report_directory_path variable (/data/public/ENV_SYNC/MasterSync/).
BASE=$base_report_directory_path/{TS}
mkdir -p $BASE
3.	Create internal structure:
BASE/tmp/
BASE/logs/
BASE/reports/
BASE/sqlite.db
E. MASTER FOLDER PREPARATION
Step-by-step Algorithm
1.	conf/conf_path.json → GitHub_Master_path variable
GitHub_Master_path=/data/code/GitHub_SFDC/Master/SFDC/
2.	Folder normalization:
3.	Log "Master prepared".
F. PROD DUMP EXTRACTION
Algorithm
1.	Identify latest zip inside /backup/PROD_DUMP/
o	Sort by date inside filename.
o	Pick highest date.
2.	Unzip to:
unzip latest.zip tmp/prod_xxx
3.	Rename:
mv tmp/prod_xxx tmp/PROD_DUMP
G. FOLDER VALIDATION
Algorithm
1.	Read expected metadata types list:
conf/conf_path.json  required_prod_components=/software/codedev/misc_script/SFDC/BCompareScript/component_main.list
2.	Read metadata types from:
tmp/PROD_DUMP/
3.	Compare:
•	Missing folder in PROD or missing folder in $required_prod_components
•	Extra folder in PROD or Extra folder in $required_prod_components
4.	If discrepancies:
•	Mark run FAILED_FOLDER_VALIDATION
•	Log stdout/stderr to DB + failure UI
•	Show the failure notification in /dashboard UI and /master_sync
•	Send a mail to conf/setup.json  email_cc variable’s recipient list. (use mutt command to send mail)
•	STOP.
3. DIFF ENGINE (MASTER vs PROD)
Preparation
Algorithm
•	Move prepared folders into TS directory:
mv tmp/Master $BASE/Master
mv tmp/PROD_DUMP $BASE/PROD_DUMP
	
•	Now structure is:
MasterSync/{TS}/Master/
MasterSync/{TS}/PROD_DUMP/
A. File List Acquisition
Algorithm
1.	Recursively list all files under:
o	Master/
o	PROD_DUMP/
2.	Normalize paths into metadata-type-based structures.
B. Categorize Files
Algorithm
For each file in PROD:
•	If not in Master → ProdMissingMaster
For each file in Master:
•	If not in PROD → MasterMissingProd
For each file present in both:
•	Compare content:
o	If different → CommonDiff
o	Else ignore.
Store each list in SQLite tables:
•	prod_missing_master
•	master_missing_prod
•	common_diff
C. Combined Changed + Missing
Algorithm
1.	Combine:
o	CommonDiff
o	ProdMissingMaster (because "missing in Master" = will be newly added in Master)
2.	For each file in combined set:
o	Run:
sf metadata:info -m <metadata path>
•	Extract:
o	lastModifiedBy
o	lastModifiedDate
3.	Insert into table combined_changes.
4. CODE COMPARISON (Beyond Compare)
Algorithm
1.	Run:
bash codecompare.posix2.sh -d -m oo -o Master -o PROD_DUMP
2.	Script generates:
•	Diff folders
•	HTML summary
3.	Store link in DB and UI.
5. CREATE /Master_Update_Files STRUCTURE
Algorithm
If Master Sync succeeded:
1.	Create:
mkdir BASE/Master_Update_Files
2.	From:
common_diff
prod_missing_master
3.	Recreate Master folder structure.
4.	Copy relevant files from Master folder using relative path mapping.

6. EMAIL NOTIFICATION
Algorithm
1.	Build email body:
o	TS folder link
o	Summary counts
2.	Execute:
echo "$BODY" | mutt -s "$SUBJECT" $EMAIL_LIST
3.	Log email status.

7. UPDATE DATABASE FOR UI
Algorithm
Insert into table master_sync_runs:
•	timestamp
•	success/fail
•	prod dump name
•	master summary counts
•	folder validation status
•	code compare link
•	csv links
•	execution duration


8. UI RENDERING — MASTER SYNC PAGE
Algorithm
1.	Query master_sync_runs for:
o	Latest run → Build cards
o	Last 20 runs → Build history table
2.	Render:
o	Duration
o	API Version (from prod dump)
o	CSV download buttons
o	Code Compare button
o	Master Dump link
o	Prod Dump link
9. BRANCH SYNC MODULE
A. Extract Live Branches (“sbx”, “tst”, “hfx”)
Algorithm
Read ~/.bashrc.
Search lines matching:
•	alias sbx=
•	alias tst=
•	alias hfx=
Extract branch name from path:
Example:
/data/code/GitHub_SFDC/sfdc_deploySBX/<BRANCH>/SFDC/
→ <BRANCH>
Populate UI list.
B. User Chooses Branch or “All Branches”
Algorithm
On submit:
1.	For each selected branch:
o	Run full diff vs Master Sync’s combined_changes.
________________________________________
C. Branch Diff Calculation
Algorithm
For selected branch:
1.	Prepare branch folder:
o	Copy from Git folder into TS/Branch folder.
2.	Compare:
o	Files in Master missing in Branch
o	Files in Branch missing in Master
o	Common files → content different
3.	Determine Combined Changed + Missing:
o	Union of all above
o	For each:
	Extract last 5 authors:
git log -n 5 --pretty=format:"%an|%ad" -- <file>
4.	Store into branch_sync_runs table.
D. If “All Branches”
Algorithm
Run the above workflow 3 times:
•	sbx branch
•	tst branch
•	hfx branch
Render 3 report cards.
________________________________________
E. Branch Sync UI Rendering
Algorithm
1.	For each branch report:
o	Show Duration
o	Files missing in Master
o	Files missing in Branch
o	Common diff
o	Combined changes list
o	Author log list
o	Code Compare links
2.	History table from branch_sync_runs.

